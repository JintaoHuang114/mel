Global seed set to 43
/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/root/miniconda3/lib/python3.8/site-packages/transformers/models/clip/processing_clip.py:142: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.
  warnings.warn(
PreProcessing: 100%|██████████████████| 109976/109976 [00:18<00:00, 5968.99it/s]
PreProcessing: 100%|████████████████████| 18092/18092 [00:03<00:00, 5101.94it/s]
PreProcessing: 100%|██████████████████████| 2585/2585 [00:00<00:00, 5852.94it/s]
PreProcessing: 100%|██████████████████████| 5169/5169 [00:00<00:00, 5823.14it/s]
/root/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:267: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['ckpt_encoder.clip.logit_scale', 'ckpt_encoder.clip.text_model.embeddings.position_ids', 'ckpt_encoder.clip.text_model.embeddings.token_embedding.weight', 'ckpt_encoder.clip.text_model.embeddings.position_embedding.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.layer_norm2.bias', 'ckpt_encoder.clip.text_model.final_layer_norm.weight', 'ckpt_encoder.clip.text_model.final_layer_norm.bias', 'ckpt_encoder.clip.vision_model.embeddings.class_embedding', 'ckpt_encoder.clip.vision_model.embeddings.position_ids', 'ckpt_encoder.clip.vision_model.embeddings.patch_embedding.weight', 'ckpt_encoder.clip.vision_model.embeddings.position_embedding.weight', 'ckpt_encoder.clip.vision_model.pre_layrnorm.weight', 'ckpt_encoder.clip.vision_model.pre_layrnorm.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.post_layernorm.weight', 'ckpt_encoder.clip.vision_model.post_layernorm.bias', 'ckpt_encoder.clip.visual_projection.weight', 'ckpt_encoder.clip.text_projection.weight', 'ckpt_encoder.image_cls_fc.weight', 'ckpt_encoder.image_cls_fc.bias', 'ckpt_encoder.image_tokens_fc.weight', 'ckpt_encoder.image_tokens_fc.bias', 'ckpt_matcher.tglu.fc_query.weight', 'ckpt_matcher.tglu.fc_query.bias', 'ckpt_matcher.tglu.fc_key.weight', 'ckpt_matcher.tglu.fc_key.bias', 'ckpt_matcher.tglu.fc_value.weight', 'ckpt_matcher.tglu.fc_value.bias', 'ckpt_matcher.tglu.fc_cls.weight', 'ckpt_matcher.tglu.fc_cls.bias', 'ckpt_matcher.tglu.layer_norm.weight', 'ckpt_matcher.tglu.layer_norm.bias', 'ckpt_matcher.vdlu.dual_ent2men.cls_fc.weight', 'ckpt_matcher.vdlu.dual_ent2men.cls_fc.bias', 'ckpt_matcher.vdlu.dual_ent2men.tokens_fc.weight', 'ckpt_matcher.vdlu.dual_ent2men.tokens_fc.bias', 'ckpt_matcher.vdlu.dual_ent2men.fc.weight', 'ckpt_matcher.vdlu.dual_ent2men.fc.bias', 'ckpt_matcher.vdlu.dual_ent2men.gate_fc.weight', 'ckpt_matcher.vdlu.dual_ent2men.gate_fc.bias', 'ckpt_matcher.vdlu.dual_ent2men.add_layer_norm.weight', 'ckpt_matcher.vdlu.dual_ent2men.add_layer_norm.bias', 'ckpt_matcher.vdlu.dual_ent2men.layer_norm.weight', 'ckpt_matcher.vdlu.dual_ent2men.layer_norm.bias', 'ckpt_matcher.vdlu.dual_men2ent.cls_fc.weight', 'ckpt_matcher.vdlu.dual_men2ent.cls_fc.bias', 'ckpt_matcher.vdlu.dual_men2ent.tokens_fc.weight', 'ckpt_matcher.vdlu.dual_men2ent.tokens_fc.bias', 'ckpt_matcher.vdlu.dual_men2ent.fc.weight', 'ckpt_matcher.vdlu.dual_men2ent.fc.bias', 'ckpt_matcher.vdlu.dual_men2ent.gate_fc.weight', 'ckpt_matcher.vdlu.dual_men2ent.gate_fc.bias', 'ckpt_matcher.vdlu.dual_men2ent.add_layer_norm.weight', 'ckpt_matcher.vdlu.dual_men2ent.add_layer_norm.bias', 'ckpt_matcher.vdlu.dual_men2ent.layer_norm.weight', 'ckpt_matcher.vdlu.dual_men2ent.layer_norm.bias', 'ckpt_matcher.cmfu.text_fc.weight', 'ckpt_matcher.cmfu.text_fc.bias', 'ckpt_matcher.cmfu.image_fc.weight', 'ckpt_matcher.cmfu.image_fc.bias', 'ckpt_matcher.cmfu.gate_fc.weight', 'ckpt_matcher.cmfu.gate_fc.bias', 'ckpt_matcher.cmfu.gate_layer_norm.weight', 'ckpt_matcher.cmfu.gate_layer_norm.bias', 'ckpt_matcher.cmfu.context_layer_norm.weight', 'ckpt_matcher.cmfu.context_layer_norm.bias', 'ckpt_matcher.text_cls_layernorm.weight', 'ckpt_matcher.text_cls_layernorm.bias', 'ckpt_matcher.text_tokens_layernorm.weight', 'ckpt_matcher.text_tokens_layernorm.bias', 'ckpt_matcher.image_cls_layernorm.weight', 'ckpt_matcher.image_cls_layernorm.bias', 'ckpt_matcher.image_tokens_layernorm.weight', 'ckpt_matcher.image_tokens_layernorm.bias']
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Testing: 0it [00:00, ?it/s]
UpdateEmbed:   0%|                                      | 0/215 [00:00<?, ?it/s]You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.

UpdateEmbed:   0%|▏                             | 1/215 [00:03<12:12,  3.43s/it]
UpdateEmbed:   1%|▎                             | 2/215 [00:03<05:50,  1.65s/it]
UpdateEmbed:   1%|▍                             | 3/215 [00:04<03:46,  1.07s/it]
UpdateEmbed:   2%|▌                             | 4/215 [00:04<02:51,  1.23it/s]
UpdateEmbed:   2%|▋                             | 5/215 [00:05<02:23,  1.47it/s]
UpdateEmbed:   3%|▊                             | 6/215 [00:05<02:03,  1.69it/s]
UpdateEmbed:   3%|▉                             | 7/215 [00:05<01:53,  1.83it/s]
UpdateEmbed:   4%|█                             | 8/215 [00:06<01:43,  2.00it/s]
UpdateEmbed:   4%|█▎                            | 9/215 [00:06<01:47,  1.91it/s]
UpdateEmbed:   5%|█▎                           | 10/215 [00:07<01:40,  2.04it/s]
UpdateEmbed:   5%|█▍                           | 11/215 [00:07<01:34,  2.15it/s]
UpdateEmbed:   6%|█▌                           | 12/215 [00:08<01:32,  2.20it/s]
UpdateEmbed:   6%|█▊                           | 13/215 [00:08<01:32,  2.19it/s]
UpdateEmbed:   7%|█▉                           | 14/215 [00:09<01:29,  2.25it/s]
UpdateEmbed:   7%|██                           | 15/215 [00:09<01:27,  2.27it/s]
UpdateEmbed:   7%|██▏                          | 16/215 [00:09<01:25,  2.32it/s]
UpdateEmbed:   8%|██▎                          | 17/215 [00:10<01:34,  2.10it/s]
UpdateEmbed:   8%|██▍                          | 18/215 [00:10<01:30,  2.19it/s]
UpdateEmbed:   9%|██▌                          | 19/215 [00:11<01:27,  2.25it/s]
UpdateEmbed:   9%|██▋                          | 20/215 [00:11<01:24,  2.30it/s]
UpdateEmbed:  10%|██▊                          | 21/215 [00:12<01:22,  2.34it/s]
UpdateEmbed:  10%|██▉                          | 22/215 [00:12<01:21,  2.35it/s]
UpdateEmbed:  11%|███                          | 23/215 [00:12<01:20,  2.38it/s]
UpdateEmbed:  11%|███▏                         | 24/215 [00:13<01:20,  2.38it/s]
UpdateEmbed:  12%|███▎                         | 25/215 [00:13<01:19,  2.40it/s]
UpdateEmbed:  12%|███▌                         | 26/215 [00:14<01:19,  2.39it/s]
UpdateEmbed:  13%|███▋                         | 27/215 [00:14<01:18,  2.40it/s]
UpdateEmbed:  13%|███▊                         | 28/215 [00:15<01:17,  2.40it/s]
UpdateEmbed:  13%|███▉                         | 29/215 [00:15<01:18,  2.38it/s]
UpdateEmbed:  14%|████                         | 30/215 [00:15<01:17,  2.39it/s]
UpdateEmbed:  14%|████▏                        | 31/215 [00:16<01:16,  2.39it/s]
UpdateEmbed:  15%|████▎                        | 32/215 [00:16<01:16,  2.40it/s]
UpdateEmbed:  15%|████▍                        | 33/215 [00:17<01:16,  2.39it/s]
UpdateEmbed:  16%|████▌                        | 34/215 [00:17<01:16,  2.38it/s]
UpdateEmbed:  16%|████▋                        | 35/215 [00:17<01:16,  2.37it/s]
UpdateEmbed:  17%|████▊                        | 36/215 [00:18<01:15,  2.38it/s]
UpdateEmbed:  17%|████▉                        | 37/215 [00:18<01:14,  2.39it/s]
UpdateEmbed:  18%|█████▏                       | 38/215 [00:19<01:14,  2.39it/s]
UpdateEmbed:  18%|█████▎                       | 39/215 [00:19<01:13,  2.40it/s]
UpdateEmbed:  19%|█████▍                       | 40/215 [00:20<01:12,  2.40it/s]
UpdateEmbed:  19%|█████▌                       | 41/215 [00:20<01:12,  2.38it/s]
UpdateEmbed:  20%|█████▋                       | 42/215 [00:20<01:12,  2.40it/s]
UpdateEmbed:  20%|█████▊                       | 43/215 [00:21<01:11,  2.39it/s]
UpdateEmbed:  20%|█████▉                       | 44/215 [00:21<01:11,  2.39it/s]
UpdateEmbed:  21%|██████                       | 45/215 [00:22<01:11,  2.39it/s]
UpdateEmbed:  21%|██████▏                      | 46/215 [00:22<01:10,  2.40it/s]
UpdateEmbed:  22%|██████▎                      | 47/215 [00:22<01:09,  2.41it/s]
UpdateEmbed:  22%|██████▍                      | 48/215 [00:23<01:09,  2.41it/s]
UpdateEmbed:  23%|██████▌                      | 49/215 [00:23<01:09,  2.40it/s]
UpdateEmbed:  23%|██████▋                      | 50/215 [00:24<01:08,  2.39it/s]
UpdateEmbed:  24%|██████▉                      | 51/215 [00:24<01:10,  2.34it/s]
UpdateEmbed:  24%|███████                      | 52/215 [00:25<01:09,  2.35it/s]
UpdateEmbed:  25%|███████▏                     | 53/215 [00:25<01:08,  2.35it/s]
UpdateEmbed:  25%|███████▎                     | 54/215 [00:25<01:07,  2.37it/s]
UpdateEmbed:  26%|███████▍                     | 55/215 [00:26<01:06,  2.39it/s]
UpdateEmbed:  26%|███████▌                     | 56/215 [00:26<01:06,  2.39it/s]
UpdateEmbed:  27%|███████▋                     | 57/215 [00:27<01:06,  2.38it/s]
UpdateEmbed:  27%|███████▊                     | 58/215 [00:27<01:05,  2.39it/s]
UpdateEmbed:  27%|███████▉                     | 59/215 [00:28<01:05,  2.38it/s]
UpdateEmbed:  28%|████████                     | 60/215 [00:28<01:04,  2.39it/s]
UpdateEmbed:  28%|████████▏                    | 61/215 [00:28<01:04,  2.38it/s]
UpdateEmbed:  29%|████████▎                    | 62/215 [00:29<01:04,  2.37it/s]
UpdateEmbed:  29%|████████▍                    | 63/215 [00:29<01:03,  2.39it/s]
UpdateEmbed:  30%|████████▋                    | 64/215 [00:30<01:02,  2.40it/s]
UpdateEmbed:  30%|████████▊                    | 65/215 [00:30<01:02,  2.40it/s]
UpdateEmbed:  31%|████████▉                    | 66/215 [00:30<01:02,  2.39it/s]
UpdateEmbed:  31%|█████████                    | 67/215 [00:31<01:02,  2.38it/s]
UpdateEmbed:  32%|█████████▏                   | 68/215 [00:31<01:01,  2.40it/s]
UpdateEmbed:  32%|█████████▎                   | 69/215 [00:32<01:00,  2.41it/s]
UpdateEmbed:  33%|█████████▍                   | 70/215 [00:32<01:00,  2.41it/s]
UpdateEmbed:  33%|█████████▌                   | 71/215 [00:33<00:59,  2.43it/s]
UpdateEmbed:  33%|█████████▋                   | 72/215 [00:33<00:58,  2.43it/s]
UpdateEmbed:  34%|█████████▊                   | 73/215 [00:33<00:59,  2.39it/s]
UpdateEmbed:  34%|█████████▉                   | 74/215 [00:34<00:58,  2.39it/s]
UpdateEmbed:  35%|██████████                   | 75/215 [00:34<00:59,  2.37it/s]
UpdateEmbed:  35%|██████████▎                  | 76/215 [00:35<00:58,  2.37it/s]
UpdateEmbed:  36%|██████████▍                  | 77/215 [00:35<00:57,  2.39it/s]
UpdateEmbed:  36%|██████████▌                  | 78/215 [00:35<00:57,  2.40it/s]
UpdateEmbed:  37%|██████████▋                  | 79/215 [00:36<00:56,  2.41it/s]
UpdateEmbed:  37%|██████████▊                  | 80/215 [00:36<00:56,  2.40it/s]
UpdateEmbed:  38%|██████████▉                  | 81/215 [00:37<00:55,  2.41it/s]
UpdateEmbed:  38%|███████████                  | 82/215 [00:37<00:55,  2.40it/s]
UpdateEmbed:  39%|███████████▏                 | 83/215 [00:38<00:57,  2.30it/s]
UpdateEmbed:  39%|███████████▎                 | 84/215 [00:38<00:56,  2.31it/s]
UpdateEmbed:  40%|███████████▍                 | 85/215 [00:38<00:55,  2.35it/s]
UpdateEmbed:  40%|███████████▌                 | 86/215 [00:39<00:54,  2.37it/s]
UpdateEmbed:  40%|███████████▋                 | 87/215 [00:39<00:53,  2.37it/s]
UpdateEmbed:  41%|███████████▊                 | 88/215 [00:40<00:53,  2.37it/s]
UpdateEmbed:  41%|████████████                 | 89/215 [00:40<00:54,  2.33it/s]
UpdateEmbed:  42%|████████████▏                | 90/215 [00:41<00:53,  2.35it/s]
UpdateEmbed:  42%|████████████▎                | 91/215 [00:41<00:52,  2.35it/s]
UpdateEmbed:  43%|████████████▍                | 92/215 [00:41<00:51,  2.37it/s]
UpdateEmbed:  43%|████████████▌                | 93/215 [00:42<00:51,  2.39it/s]
UpdateEmbed:  44%|████████████▋                | 94/215 [00:42<00:50,  2.38it/s]
UpdateEmbed:  44%|████████████▊                | 95/215 [00:43<00:50,  2.37it/s]
UpdateEmbed:  45%|████████████▉                | 96/215 [00:43<00:50,  2.38it/s]
UpdateEmbed:  45%|█████████████                | 97/215 [00:44<00:50,  2.34it/s]
UpdateEmbed:  46%|█████████████▏               | 98/215 [00:44<00:49,  2.36it/s]
UpdateEmbed:  46%|█████████████▎               | 99/215 [00:44<00:49,  2.34it/s]
UpdateEmbed:  47%|█████████████               | 100/215 [00:45<00:48,  2.37it/s]
UpdateEmbed:  47%|█████████████▏              | 101/215 [00:45<00:47,  2.38it/s]
UpdateEmbed:  47%|█████████████▎              | 102/215 [00:46<00:47,  2.38it/s]
UpdateEmbed:  48%|█████████████▍              | 103/215 [00:46<00:47,  2.36it/s]
UpdateEmbed:  48%|█████████████▌              | 104/215 [00:46<00:46,  2.38it/s]
UpdateEmbed:  49%|█████████████▋              | 105/215 [00:47<00:46,  2.38it/s]
UpdateEmbed:  49%|█████████████▊              | 106/215 [00:47<00:45,  2.38it/s]
UpdateEmbed:  50%|█████████████▉              | 107/215 [00:48<00:47,  2.28it/s]
UpdateEmbed:  50%|██████████████              | 108/215 [00:48<00:45,  2.33it/s]
UpdateEmbed:  51%|██████████████▏             | 109/215 [00:49<00:45,  2.35it/s]
UpdateEmbed:  51%|██████████████▎             | 110/215 [00:49<00:44,  2.37it/s]
UpdateEmbed:  52%|██████████████▍             | 111/215 [00:49<00:43,  2.40it/s]
UpdateEmbed:  52%|██████████████▌             | 112/215 [00:50<00:42,  2.42it/s]
UpdateEmbed:  53%|██████████████▋             | 113/215 [00:50<00:42,  2.41it/s]
UpdateEmbed:  53%|██████████████▊             | 114/215 [00:51<00:41,  2.41it/s]
UpdateEmbed:  53%|██████████████▉             | 115/215 [00:51<00:42,  2.34it/s]
UpdateEmbed:  54%|███████████████             | 116/215 [00:52<00:41,  2.37it/s]
UpdateEmbed:  54%|███████████████▏            | 117/215 [00:52<00:41,  2.37it/s]
UpdateEmbed:  55%|███████████████▎            | 118/215 [00:52<00:40,  2.39it/s]
UpdateEmbed:  55%|███████████████▍            | 119/215 [00:53<00:39,  2.41it/s]
UpdateEmbed:  56%|███████████████▋            | 120/215 [00:53<00:39,  2.38it/s]
UpdateEmbed:  56%|███████████████▊            | 121/215 [00:54<00:40,  2.31it/s]
UpdateEmbed:  57%|███████████████▉            | 122/215 [00:54<00:39,  2.35it/s]
UpdateEmbed:  57%|████████████████            | 123/215 [00:55<00:39,  2.31it/s]
UpdateEmbed:  58%|████████████████▏           | 124/215 [00:55<00:38,  2.34it/s]
UpdateEmbed:  58%|████████████████▎           | 125/215 [00:55<00:38,  2.32it/s]
UpdateEmbed:  59%|████████████████▍           | 126/215 [00:56<00:38,  2.33it/s]
UpdateEmbed:  59%|████████████████▌           | 127/215 [00:56<00:37,  2.37it/s]
UpdateEmbed:  60%|████████████████▋           | 128/215 [00:57<00:36,  2.39it/s]
UpdateEmbed:  60%|████████████████▊           | 129/215 [00:57<00:36,  2.39it/s]
UpdateEmbed:  60%|████████████████▉           | 130/215 [00:57<00:35,  2.39it/s]
UpdateEmbed:  61%|█████████████████           | 131/215 [00:58<00:36,  2.32it/s]
UpdateEmbed:  61%|█████████████████▏          | 132/215 [00:58<00:35,  2.35it/s]
UpdateEmbed:  62%|█████████████████▎          | 133/215 [00:59<00:35,  2.30it/s]
UpdateEmbed:  62%|█████████████████▍          | 134/215 [00:59<00:34,  2.34it/s]
UpdateEmbed:  63%|█████████████████▌          | 135/215 [01:00<00:33,  2.37it/s]
UpdateEmbed:  63%|█████████████████▋          | 136/215 [01:00<00:33,  2.39it/s]
UpdateEmbed:  64%|█████████████████▊          | 137/215 [01:00<00:32,  2.39it/s]
UpdateEmbed:  64%|█████████████████▉          | 138/215 [01:01<00:32,  2.40it/s]
UpdateEmbed:  65%|██████████████████          | 139/215 [01:01<00:31,  2.38it/s]
UpdateEmbed:  65%|██████████████████▏         | 140/215 [01:02<00:31,  2.39it/s]
UpdateEmbed:  66%|██████████████████▎         | 141/215 [01:02<00:32,  2.30it/s]
UpdateEmbed:  66%|██████████████████▍         | 142/215 [01:03<00:31,  2.31it/s]
UpdateEmbed:  67%|██████████████████▌         | 143/215 [01:03<00:30,  2.33it/s]
UpdateEmbed:  67%|██████████████████▊         | 144/215 [01:03<00:30,  2.35it/s]
UpdateEmbed:  67%|██████████████████▉         | 145/215 [01:04<00:29,  2.36it/s]
UpdateEmbed:  68%|███████████████████         | 146/215 [01:04<00:29,  2.37it/s]
UpdateEmbed:  68%|███████████████████▏        | 147/215 [01:05<00:29,  2.30it/s]
UpdateEmbed:  69%|███████████████████▎        | 148/215 [01:05<00:28,  2.34it/s]
UpdateEmbed:  69%|███████████████████▍        | 149/215 [01:06<00:28,  2.32it/s]
UpdateEmbed:  70%|███████████████████▌        | 150/215 [01:06<00:28,  2.32it/s]
UpdateEmbed:  70%|███████████████████▋        | 151/215 [01:06<00:27,  2.33it/s]
UpdateEmbed:  71%|███████████████████▊        | 152/215 [01:07<00:26,  2.35it/s]
UpdateEmbed:  71%|███████████████████▉        | 153/215 [01:07<00:26,  2.37it/s]
UpdateEmbed:  72%|████████████████████        | 154/215 [01:08<00:25,  2.36it/s]
UpdateEmbed:  72%|████████████████████▏       | 155/215 [01:08<00:26,  2.30it/s]
UpdateEmbed:  73%|████████████████████▎       | 156/215 [01:09<00:25,  2.33it/s]
UpdateEmbed:  73%|████████████████████▍       | 157/215 [01:09<00:25,  2.29it/s]
UpdateEmbed:  73%|████████████████████▌       | 158/215 [01:09<00:24,  2.30it/s]
UpdateEmbed:  74%|████████████████████▋       | 159/215 [01:10<00:24,  2.27it/s]
UpdateEmbed:  74%|████████████████████▊       | 160/215 [01:10<00:23,  2.30it/s]
UpdateEmbed:  75%|████████████████████▉       | 161/215 [01:11<00:23,  2.34it/s]
UpdateEmbed:  75%|█████████████████████       | 162/215 [01:11<00:22,  2.35it/s]
UpdateEmbed:  76%|█████████████████████▏      | 163/215 [01:12<00:22,  2.35it/s]
UpdateEmbed:  76%|█████████████████████▎      | 164/215 [01:12<00:21,  2.39it/s]
UpdateEmbed:  77%|█████████████████████▍      | 165/215 [01:12<00:21,  2.33it/s]
UpdateEmbed:  77%|█████████████████████▌      | 166/215 [01:13<00:20,  2.34it/s]
UpdateEmbed:  78%|█████████████████████▋      | 167/215 [01:13<00:20,  2.31it/s]
UpdateEmbed:  78%|█████████████████████▉      | 168/215 [01:14<00:19,  2.36it/s]
UpdateEmbed:  79%|██████████████████████      | 169/215 [01:14<00:19,  2.34it/s]
UpdateEmbed:  79%|██████████████████████▏     | 170/215 [01:15<00:18,  2.37it/s]
UpdateEmbed:  80%|██████████████████████▎     | 171/215 [01:15<00:18,  2.36it/s]
UpdateEmbed:  80%|██████████████████████▍     | 172/215 [01:15<00:17,  2.40it/s]
UpdateEmbed:  80%|██████████████████████▌     | 173/215 [01:16<00:18,  2.33it/s]
UpdateEmbed:  81%|██████████████████████▋     | 174/215 [01:16<00:17,  2.33it/s]
UpdateEmbed:  81%|██████████████████████▊     | 175/215 [01:17<00:17,  2.28it/s]
UpdateEmbed:  82%|██████████████████████▉     | 176/215 [01:17<00:16,  2.32it/s]
UpdateEmbed:  82%|███████████████████████     | 177/215 [01:18<00:16,  2.34it/s]
UpdateEmbed:  83%|███████████████████████▏    | 178/215 [01:18<00:15,  2.37it/s]
UpdateEmbed:  83%|███████████████████████▎    | 179/215 [01:18<00:15,  2.34it/s]
UpdateEmbed:  84%|███████████████████████▍    | 180/215 [01:19<00:14,  2.36it/s]
UpdateEmbed:  84%|███████████████████████▌    | 181/215 [01:19<00:14,  2.31it/s]
UpdateEmbed:  85%|███████████████████████▋    | 182/215 [01:20<00:14,  2.32it/s]
UpdateEmbed:  85%|███████████████████████▊    | 183/215 [01:20<00:13,  2.29it/s]
UpdateEmbed:  86%|███████████████████████▉    | 184/215 [01:21<00:13,  2.32it/s]
UpdateEmbed:  86%|████████████████████████    | 185/215 [01:21<00:12,  2.34it/s]
UpdateEmbed:  87%|████████████████████████▏   | 186/215 [01:21<00:12,  2.36it/s]
UpdateEmbed:  87%|████████████████████████▎   | 187/215 [01:22<00:12,  2.32it/s]
UpdateEmbed:  87%|████████████████████████▍   | 188/215 [01:22<00:11,  2.35it/s]
UpdateEmbed:  88%|████████████████████████▌   | 189/215 [01:23<00:11,  2.29it/s]
UpdateEmbed:  88%|████████████████████████▋   | 190/215 [01:23<00:10,  2.33it/s]
UpdateEmbed:  89%|████████████████████████▊   | 191/215 [01:24<00:10,  2.31it/s]
UpdateEmbed:  89%|█████████████████████████   | 192/215 [01:24<00:09,  2.35it/s]
UpdateEmbed:  90%|█████████████████████████▏  | 193/215 [01:24<00:09,  2.37it/s]
UpdateEmbed:  90%|█████████████████████████▎  | 194/215 [01:25<00:08,  2.39it/s]
UpdateEmbed:  91%|█████████████████████████▍  | 195/215 [01:25<00:08,  2.37it/s]
UpdateEmbed:  91%|█████████████████████████▌  | 196/215 [01:26<00:07,  2.39it/s]
UpdateEmbed:  92%|█████████████████████████▋  | 197/215 [01:26<00:07,  2.31it/s]
UpdateEmbed:  92%|█████████████████████████▊  | 198/215 [01:27<00:07,  2.31it/s]
UpdateEmbed:  93%|█████████████████████████▉  | 199/215 [01:27<00:06,  2.30it/s]
UpdateEmbed:  93%|██████████████████████████  | 200/215 [01:27<00:06,  2.31it/s]
UpdateEmbed:  93%|██████████████████████████▏ | 201/215 [01:28<00:05,  2.35it/s]
UpdateEmbed:  94%|██████████████████████████▎ | 202/215 [01:28<00:05,  2.35it/s]
UpdateEmbed:  94%|██████████████████████████▍ | 203/215 [01:29<00:05,  2.36it/s]
UpdateEmbed:  95%|██████████████████████████▌ | 204/215 [01:29<00:04,  2.40it/s]
UpdateEmbed:  95%|██████████████████████████▋ | 205/215 [01:29<00:04,  2.43it/s]
UpdateEmbed:  96%|██████████████████████████▊ | 206/215 [01:30<00:03,  2.48it/s]
UpdateEmbed:  96%|██████████████████████████▉ | 207/215 [01:30<00:03,  2.50it/s]
UpdateEmbed:  97%|███████████████████████████ | 208/215 [01:31<00:02,  2.53it/s]
UpdateEmbed:  97%|███████████████████████████▏| 209/215 [01:31<00:02,  2.55it/s]
UpdateEmbed:  98%|███████████████████████████▎| 210/215 [01:31<00:01,  2.56it/s]
UpdateEmbed:  98%|███████████████████████████▍| 211/215 [01:32<00:01,  2.56it/s]
UpdateEmbed:  99%|███████████████████████████▌| 212/215 [01:32<00:01,  2.58it/s]
UpdateEmbed:  99%|███████████████████████████▋| 213/215 [01:33<00:00,  2.57it/s]
UpdateEmbed: 100%|███████████████████████████▊| 214/215 [01:33<00:00,  2.57it/s]
UpdateEmbed: 100%|████████████████████████████| 215/215 [01:33<00:00,  2.29it/s]
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Testing DataLoader 0: 100%|███████████████████| 259/259 [21:36<00:00,  5.01s/it]
────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────
       Test/hits1           0.9214548268523892
       Test/hits10          0.9849100406268136
       Test/hits20          0.9903269491197524
       Test/hits3           0.9678854710775778
       Test/hits5           0.9750435287289612
         Test/mr             13.04062681369704
        Test/mrr            0.9466201520316874
────────────────────────────────────────────────────────────────────────────────

Process finished with exit code 0
