Global seed set to 43
/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/root/miniconda3/lib/python3.8/site-packages/transformers/models/clip/processing_clip.py:142: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.
  warnings.warn(
PreProcessing: 100%|██████████████████| 132460/132460 [00:24<00:00, 5357.13it/s]
PreProcessing: 100%|████████████████████| 11351/11351 [00:02<00:00, 5618.31it/s]
PreProcessing: 100%|██████████████████████| 1664/1664 [00:00<00:00, 5756.54it/s]
PreProcessing: 100%|██████████████████████| 2078/2078 [00:00<00:00, 5727.42it/s]
/root/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:267: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['ckpt_encoder.clip.logit_scale', 'ckpt_encoder.clip.text_model.embeddings.position_ids', 'ckpt_encoder.clip.text_model.embeddings.token_embedding.weight', 'ckpt_encoder.clip.text_model.embeddings.position_embedding.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.0.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.0.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.1.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.1.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.2.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.2.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.3.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.3.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.4.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.4.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.5.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.5.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.6.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.6.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.7.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.7.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.8.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.8.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.9.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.9.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.10.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.10.layer_norm2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.k_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.k_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.v_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.v_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.q_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.q_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.out_proj.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.self_attn.out_proj.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.layer_norm1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.layer_norm1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.mlp.fc1.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.mlp.fc1.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.mlp.fc2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.mlp.fc2.bias', 'ckpt_encoder.clip.text_model.encoder.layers.11.layer_norm2.weight', 'ckpt_encoder.clip.text_model.encoder.layers.11.layer_norm2.bias', 'ckpt_encoder.clip.text_model.final_layer_norm.weight', 'ckpt_encoder.clip.text_model.final_layer_norm.bias', 'ckpt_encoder.clip.vision_model.embeddings.class_embedding', 'ckpt_encoder.clip.vision_model.embeddings.position_ids', 'ckpt_encoder.clip.vision_model.embeddings.patch_embedding.weight', 'ckpt_encoder.clip.vision_model.embeddings.position_embedding.weight', 'ckpt_encoder.clip.vision_model.pre_layrnorm.weight', 'ckpt_encoder.clip.vision_model.pre_layrnorm.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.0.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.0.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.1.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.1.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.2.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.2.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.3.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.3.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.4.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.4.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.5.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.5.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.6.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.6.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.7.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.7.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.8.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.8.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.9.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.9.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.10.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.10.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.layer_norm1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.layer_norm1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.mlp.fc1.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.mlp.fc1.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.mlp.fc2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.mlp.fc2.bias', 'ckpt_encoder.clip.vision_model.encoder.layers.11.layer_norm2.weight', 'ckpt_encoder.clip.vision_model.encoder.layers.11.layer_norm2.bias', 'ckpt_encoder.clip.vision_model.post_layernorm.weight', 'ckpt_encoder.clip.vision_model.post_layernorm.bias', 'ckpt_encoder.clip.visual_projection.weight', 'ckpt_encoder.clip.text_projection.weight', 'ckpt_encoder.image_cls_fc.weight', 'ckpt_encoder.image_cls_fc.bias', 'ckpt_encoder.image_tokens_fc.weight', 'ckpt_encoder.image_tokens_fc.bias', 'ckpt_matcher.tglu.fc_query.weight', 'ckpt_matcher.tglu.fc_query.bias', 'ckpt_matcher.tglu.fc_key.weight', 'ckpt_matcher.tglu.fc_key.bias', 'ckpt_matcher.tglu.fc_value.weight', 'ckpt_matcher.tglu.fc_value.bias', 'ckpt_matcher.tglu.fc_cls.weight', 'ckpt_matcher.tglu.fc_cls.bias', 'ckpt_matcher.tglu.layer_norm.weight', 'ckpt_matcher.tglu.layer_norm.bias', 'ckpt_matcher.vdlu.dual_ent2men.cls_fc.weight', 'ckpt_matcher.vdlu.dual_ent2men.cls_fc.bias', 'ckpt_matcher.vdlu.dual_ent2men.tokens_fc.weight', 'ckpt_matcher.vdlu.dual_ent2men.tokens_fc.bias', 'ckpt_matcher.vdlu.dual_ent2men.fc.weight', 'ckpt_matcher.vdlu.dual_ent2men.fc.bias', 'ckpt_matcher.vdlu.dual_ent2men.gate_fc.weight', 'ckpt_matcher.vdlu.dual_ent2men.gate_fc.bias', 'ckpt_matcher.vdlu.dual_ent2men.add_layer_norm.weight', 'ckpt_matcher.vdlu.dual_ent2men.add_layer_norm.bias', 'ckpt_matcher.vdlu.dual_ent2men.layer_norm.weight', 'ckpt_matcher.vdlu.dual_ent2men.layer_norm.bias', 'ckpt_matcher.vdlu.dual_men2ent.cls_fc.weight', 'ckpt_matcher.vdlu.dual_men2ent.cls_fc.bias', 'ckpt_matcher.vdlu.dual_men2ent.tokens_fc.weight', 'ckpt_matcher.vdlu.dual_men2ent.tokens_fc.bias', 'ckpt_matcher.vdlu.dual_men2ent.fc.weight', 'ckpt_matcher.vdlu.dual_men2ent.fc.bias', 'ckpt_matcher.vdlu.dual_men2ent.gate_fc.weight', 'ckpt_matcher.vdlu.dual_men2ent.gate_fc.bias', 'ckpt_matcher.vdlu.dual_men2ent.add_layer_norm.weight', 'ckpt_matcher.vdlu.dual_men2ent.add_layer_norm.bias', 'ckpt_matcher.vdlu.dual_men2ent.layer_norm.weight', 'ckpt_matcher.vdlu.dual_men2ent.layer_norm.bias', 'ckpt_matcher.cmfu.text_fc.weight', 'ckpt_matcher.cmfu.text_fc.bias', 'ckpt_matcher.cmfu.image_fc.weight', 'ckpt_matcher.cmfu.image_fc.bias', 'ckpt_matcher.cmfu.gate_fc.weight', 'ckpt_matcher.cmfu.gate_fc.bias', 'ckpt_matcher.cmfu.gate_layer_norm.weight', 'ckpt_matcher.cmfu.gate_layer_norm.bias', 'ckpt_matcher.cmfu.context_layer_norm.weight', 'ckpt_matcher.cmfu.context_layer_norm.bias', 'ckpt_matcher.text_cls_layernorm.weight', 'ckpt_matcher.text_cls_layernorm.bias', 'ckpt_matcher.text_tokens_layernorm.weight', 'ckpt_matcher.text_tokens_layernorm.bias', 'ckpt_matcher.image_cls_layernorm.weight', 'ckpt_matcher.image_cls_layernorm.bias', 'ckpt_matcher.image_tokens_layernorm.weight', 'ckpt_matcher.image_tokens_layernorm.bias']
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Testing: 0it [00:00, ?it/s]
UpdateEmbed:   0%|                                      | 0/259 [00:00<?, ?it/s]You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.

UpdateEmbed:   0%|                              | 1/259 [00:03<14:58,  3.48s/it]
UpdateEmbed:   1%|▏                             | 2/259 [00:03<07:10,  1.67s/it]
UpdateEmbed:   1%|▎                             | 3/259 [00:04<04:41,  1.10s/it]
UpdateEmbed:   2%|▍                             | 4/259 [00:04<03:32,  1.20it/s]
UpdateEmbed:   2%|▌                             | 5/259 [00:05<02:52,  1.47it/s]
UpdateEmbed:   2%|▋                             | 6/259 [00:05<02:28,  1.71it/s]
UpdateEmbed:   3%|▊                             | 7/259 [00:05<02:11,  1.92it/s]
UpdateEmbed:   3%|▉                             | 8/259 [00:06<02:00,  2.09it/s]
UpdateEmbed:   3%|█                             | 9/259 [00:06<01:54,  2.19it/s]
UpdateEmbed:   4%|█                            | 10/259 [00:07<01:50,  2.26it/s]
UpdateEmbed:   4%|█▏                           | 11/259 [00:07<01:47,  2.32it/s]
UpdateEmbed:   5%|█▎                           | 12/259 [00:07<01:44,  2.35it/s]
UpdateEmbed:   5%|█▍                           | 13/259 [00:08<01:42,  2.40it/s]
UpdateEmbed:   5%|█▌                           | 14/259 [00:08<01:41,  2.42it/s]
UpdateEmbed:   6%|█▋                           | 15/259 [00:09<01:40,  2.42it/s]
UpdateEmbed:   6%|█▊                           | 16/259 [00:09<01:40,  2.42it/s]
UpdateEmbed:   7%|█▉                           | 17/259 [00:09<01:40,  2.42it/s]
UpdateEmbed:   7%|██                           | 18/259 [00:10<01:39,  2.42it/s]
UpdateEmbed:   7%|██▏                          | 19/259 [00:10<01:39,  2.42it/s]
UpdateEmbed:   8%|██▏                          | 20/259 [00:11<01:38,  2.42it/s]
UpdateEmbed:   8%|██▎                          | 21/259 [00:11<01:38,  2.42it/s]
UpdateEmbed:   8%|██▍                          | 22/259 [00:12<01:38,  2.41it/s]
UpdateEmbed:   9%|██▌                          | 23/259 [00:12<01:38,  2.39it/s]
UpdateEmbed:   9%|██▋                          | 24/259 [00:12<01:37,  2.41it/s]
UpdateEmbed:  10%|██▊                          | 25/259 [00:13<01:37,  2.40it/s]
UpdateEmbed:  10%|██▉                          | 26/259 [00:13<01:36,  2.42it/s]
UpdateEmbed:  10%|███                          | 27/259 [00:14<01:35,  2.43it/s]
UpdateEmbed:  11%|███▏                         | 28/259 [00:14<01:35,  2.43it/s]
UpdateEmbed:  11%|███▏                         | 29/259 [00:14<01:33,  2.45it/s]
UpdateEmbed:  12%|███▎                         | 30/259 [00:15<01:33,  2.45it/s]
UpdateEmbed:  12%|███▍                         | 31/259 [00:15<01:33,  2.43it/s]
UpdateEmbed:  12%|███▌                         | 32/259 [00:16<01:33,  2.43it/s]
UpdateEmbed:  13%|███▋                         | 33/259 [00:16<01:32,  2.43it/s]
UpdateEmbed:  13%|███▊                         | 34/259 [00:17<01:32,  2.43it/s]
UpdateEmbed:  14%|███▉                         | 35/259 [00:17<01:33,  2.40it/s]
UpdateEmbed:  14%|████                         | 36/259 [00:17<01:33,  2.40it/s]
UpdateEmbed:  14%|████▏                        | 37/259 [00:18<01:32,  2.41it/s]
UpdateEmbed:  15%|████▎                        | 38/259 [00:18<01:32,  2.40it/s]
UpdateEmbed:  15%|████▎                        | 39/259 [00:19<01:31,  2.39it/s]
UpdateEmbed:  15%|████▍                        | 40/259 [00:19<01:31,  2.39it/s]
UpdateEmbed:  16%|████▌                        | 41/259 [00:19<01:31,  2.39it/s]
UpdateEmbed:  16%|████▋                        | 42/259 [00:20<01:30,  2.40it/s]
UpdateEmbed:  17%|████▊                        | 43/259 [00:20<01:30,  2.38it/s]
UpdateEmbed:  17%|████▉                        | 44/259 [00:21<01:30,  2.37it/s]
UpdateEmbed:  17%|█████                        | 45/259 [00:21<01:30,  2.35it/s]
UpdateEmbed:  18%|█████▏                       | 46/259 [00:22<01:31,  2.34it/s]
UpdateEmbed:  18%|█████▎                       | 47/259 [00:22<01:30,  2.34it/s]
UpdateEmbed:  19%|█████▎                       | 48/259 [00:22<01:30,  2.33it/s]
UpdateEmbed:  19%|█████▍                       | 49/259 [00:23<01:28,  2.38it/s]
UpdateEmbed:  19%|█████▌                       | 50/259 [00:23<01:26,  2.40it/s]
UpdateEmbed:  20%|█████▋                       | 51/259 [00:24<01:27,  2.37it/s]
UpdateEmbed:  20%|█████▊                       | 52/259 [00:24<01:28,  2.33it/s]
UpdateEmbed:  20%|█████▉                       | 53/259 [00:25<01:29,  2.30it/s]
UpdateEmbed:  21%|██████                       | 54/259 [00:25<01:28,  2.31it/s]
UpdateEmbed:  21%|██████▏                      | 55/259 [00:25<01:28,  2.31it/s]
UpdateEmbed:  22%|██████▎                      | 56/259 [00:26<01:27,  2.33it/s]
UpdateEmbed:  22%|██████▍                      | 57/259 [00:26<01:25,  2.37it/s]
UpdateEmbed:  22%|██████▍                      | 58/259 [00:27<01:25,  2.35it/s]
UpdateEmbed:  23%|██████▌                      | 59/259 [00:27<01:26,  2.32it/s]
UpdateEmbed:  23%|██████▋                      | 60/259 [00:28<01:27,  2.26it/s]
UpdateEmbed:  24%|██████▊                      | 61/259 [00:28<01:28,  2.24it/s]
UpdateEmbed:  24%|██████▉                      | 62/259 [00:28<01:26,  2.28it/s]
UpdateEmbed:  24%|███████                      | 63/259 [00:29<01:27,  2.24it/s]
UpdateEmbed:  25%|███████▏                     | 64/259 [00:29<01:28,  2.21it/s]
UpdateEmbed:  25%|███████▎                     | 65/259 [00:30<01:26,  2.24it/s]
UpdateEmbed:  25%|███████▍                     | 66/259 [00:30<01:25,  2.27it/s]
UpdateEmbed:  26%|███████▌                     | 67/259 [00:31<01:25,  2.25it/s]
UpdateEmbed:  26%|███████▌                     | 68/259 [00:31<01:25,  2.23it/s]
UpdateEmbed:  27%|███████▋                     | 69/259 [00:32<01:27,  2.16it/s]
UpdateEmbed:  27%|███████▊                     | 70/259 [00:32<01:27,  2.16it/s]
UpdateEmbed:  27%|███████▉                     | 71/259 [00:33<01:27,  2.15it/s]
UpdateEmbed:  28%|████████                     | 72/259 [00:33<01:25,  2.19it/s]
UpdateEmbed:  28%|████████▏                    | 73/259 [00:33<01:22,  2.26it/s]
UpdateEmbed:  29%|████████▎                    | 74/259 [00:34<01:21,  2.28it/s]
UpdateEmbed:  29%|████████▍                    | 75/259 [00:34<01:22,  2.24it/s]
UpdateEmbed:  29%|████████▌                    | 76/259 [00:35<01:23,  2.20it/s]
UpdateEmbed:  30%|████████▌                    | 77/259 [00:35<01:24,  2.15it/s]
UpdateEmbed:  30%|████████▋                    | 78/259 [00:36<01:23,  2.17it/s]
UpdateEmbed:  31%|████████▊                    | 79/259 [00:36<01:23,  2.15it/s]
UpdateEmbed:  31%|████████▉                    | 80/259 [00:37<01:24,  2.11it/s]
UpdateEmbed:  31%|█████████                    | 81/259 [00:37<01:21,  2.18it/s]
UpdateEmbed:  32%|█████████▏                   | 82/259 [00:38<01:19,  2.22it/s]
UpdateEmbed:  32%|█████████▎                   | 83/259 [00:38<01:19,  2.21it/s]
UpdateEmbed:  32%|█████████▍                   | 84/259 [00:39<01:20,  2.17it/s]
UpdateEmbed:  33%|█████████▌                   | 85/259 [00:39<01:18,  2.22it/s]
UpdateEmbed:  33%|█████████▋                   | 86/259 [00:39<01:20,  2.16it/s]
UpdateEmbed:  34%|█████████▋                   | 87/259 [00:40<01:19,  2.16it/s]
UpdateEmbed:  34%|█████████▊                   | 88/259 [00:40<01:20,  2.13it/s]
UpdateEmbed:  34%|█████████▉                   | 89/259 [00:41<01:18,  2.16it/s]
UpdateEmbed:  35%|██████████                   | 90/259 [00:41<01:18,  2.16it/s]
UpdateEmbed:  35%|██████████▏                  | 91/259 [00:42<01:17,  2.16it/s]
UpdateEmbed:  36%|██████████▎                  | 92/259 [00:42<01:15,  2.20it/s]
UpdateEmbed:  36%|██████████▍                  | 93/259 [00:43<01:14,  2.23it/s]
UpdateEmbed:  36%|██████████▌                  | 94/259 [00:43<01:13,  2.26it/s]
UpdateEmbed:  37%|██████████▋                  | 95/259 [00:44<01:12,  2.25it/s]
UpdateEmbed:  37%|██████████▋                  | 96/259 [00:44<01:11,  2.29it/s]
UpdateEmbed:  37%|██████████▊                  | 97/259 [00:44<01:10,  2.29it/s]
UpdateEmbed:  38%|██████████▉                  | 98/259 [00:45<01:11,  2.26it/s]
UpdateEmbed:  38%|███████████                  | 99/259 [00:45<01:12,  2.20it/s]
UpdateEmbed:  39%|██████████▊                 | 100/259 [00:46<01:11,  2.21it/s]
UpdateEmbed:  39%|██████████▉                 | 101/259 [00:46<01:11,  2.20it/s]
UpdateEmbed:  39%|███████████                 | 102/259 [00:47<01:10,  2.23it/s]
UpdateEmbed:  40%|███████████▏                | 103/259 [00:47<01:09,  2.25it/s]
UpdateEmbed:  40%|███████████▏                | 104/259 [00:48<01:10,  2.21it/s]
UpdateEmbed:  41%|███████████▎                | 105/259 [00:48<01:09,  2.23it/s]
UpdateEmbed:  41%|███████████▍                | 106/259 [00:48<01:08,  2.25it/s]
UpdateEmbed:  41%|███████████▌                | 107/259 [00:49<01:08,  2.23it/s]
UpdateEmbed:  42%|███████████▋                | 108/259 [00:49<01:06,  2.26it/s]
UpdateEmbed:  42%|███████████▊                | 109/259 [00:50<01:06,  2.27it/s]
UpdateEmbed:  42%|███████████▉                | 110/259 [00:50<01:07,  2.21it/s]
UpdateEmbed:  43%|████████████                | 111/259 [00:51<01:06,  2.22it/s]
UpdateEmbed:  43%|████████████                | 112/259 [00:51<01:05,  2.25it/s]
UpdateEmbed:  44%|████████████▏               | 113/259 [00:52<01:03,  2.29it/s]
UpdateEmbed:  44%|████████████▎               | 114/259 [00:52<01:05,  2.22it/s]
UpdateEmbed:  44%|████████████▍               | 115/259 [00:52<01:05,  2.19it/s]
UpdateEmbed:  45%|████████████▌               | 116/259 [00:53<01:04,  2.21it/s]
UpdateEmbed:  45%|████████████▋               | 117/259 [00:53<01:04,  2.22it/s]
UpdateEmbed:  46%|████████████▊               | 118/259 [00:54<01:04,  2.19it/s]
UpdateEmbed:  46%|████████████▊               | 119/259 [00:54<01:03,  2.22it/s]
UpdateEmbed:  46%|████████████▉               | 120/259 [00:55<01:02,  2.21it/s]
UpdateEmbed:  47%|█████████████               | 121/259 [00:55<01:01,  2.26it/s]
UpdateEmbed:  47%|█████████████▏              | 122/259 [00:56<01:00,  2.28it/s]
UpdateEmbed:  47%|█████████████▎              | 123/259 [00:56<00:59,  2.28it/s]
UpdateEmbed:  48%|█████████████▍              | 124/259 [00:56<01:00,  2.25it/s]
UpdateEmbed:  48%|█████████████▌              | 125/259 [00:57<00:59,  2.24it/s]
UpdateEmbed:  49%|█████████████▌              | 126/259 [00:57<00:58,  2.26it/s]
UpdateEmbed:  49%|█████████████▋              | 127/259 [00:58<00:59,  2.22it/s]
UpdateEmbed:  49%|█████████████▊              | 128/259 [00:58<00:58,  2.24it/s]
UpdateEmbed:  50%|█████████████▉              | 129/259 [00:59<00:57,  2.27it/s]
UpdateEmbed:  50%|██████████████              | 130/259 [00:59<00:57,  2.24it/s]
UpdateEmbed:  51%|██████████████▏             | 131/259 [01:00<00:56,  2.25it/s]
UpdateEmbed:  51%|██████████████▎             | 132/259 [01:00<00:56,  2.26it/s]
UpdateEmbed:  51%|██████████████▍             | 133/259 [01:00<00:55,  2.26it/s]
UpdateEmbed:  52%|██████████████▍             | 134/259 [01:01<00:55,  2.24it/s]
UpdateEmbed:  52%|██████████████▌             | 135/259 [01:01<00:55,  2.22it/s]
UpdateEmbed:  53%|██████████████▋             | 136/259 [01:02<00:54,  2.26it/s]
UpdateEmbed:  53%|██████████████▊             | 137/259 [01:02<00:52,  2.30it/s]
UpdateEmbed:  53%|██████████████▉             | 138/259 [01:03<00:52,  2.30it/s]
UpdateEmbed:  54%|███████████████             | 139/259 [01:03<00:51,  2.32it/s]
UpdateEmbed:  54%|███████████████▏            | 140/259 [01:04<00:52,  2.27it/s]
UpdateEmbed:  54%|███████████████▏            | 141/259 [01:04<00:53,  2.21it/s]
UpdateEmbed:  55%|███████████████▎            | 142/259 [01:04<00:52,  2.22it/s]
UpdateEmbed:  55%|███████████████▍            | 143/259 [01:05<00:52,  2.21it/s]
UpdateEmbed:  56%|███████████████▌            | 144/259 [01:05<00:52,  2.18it/s]
UpdateEmbed:  56%|███████████████▋            | 145/259 [01:06<00:52,  2.17it/s]
UpdateEmbed:  56%|███████████████▊            | 146/259 [01:06<00:51,  2.20it/s]
UpdateEmbed:  57%|███████████████▉            | 147/259 [01:07<00:50,  2.21it/s]
UpdateEmbed:  57%|████████████████            | 148/259 [01:07<00:49,  2.23it/s]
UpdateEmbed:  58%|████████████████            | 149/259 [01:08<00:49,  2.20it/s]
UpdateEmbed:  58%|████████████████▏           | 150/259 [01:08<00:49,  2.21it/s]
UpdateEmbed:  58%|████████████████▎           | 151/259 [01:09<00:48,  2.22it/s]
UpdateEmbed:  59%|████████████████▍           | 152/259 [01:09<00:47,  2.26it/s]
UpdateEmbed:  59%|████████████████▌           | 153/259 [01:09<00:47,  2.24it/s]
UpdateEmbed:  59%|████████████████▋           | 154/259 [01:10<00:46,  2.25it/s]
UpdateEmbed:  60%|████████████████▊           | 155/259 [01:10<00:46,  2.23it/s]
UpdateEmbed:  60%|████████████████▊           | 156/259 [01:11<00:46,  2.20it/s]
UpdateEmbed:  61%|████████████████▉           | 157/259 [01:11<00:46,  2.18it/s]
UpdateEmbed:  61%|█████████████████           | 158/259 [01:12<00:45,  2.23it/s]
UpdateEmbed:  61%|█████████████████▏          | 159/259 [01:12<00:45,  2.21it/s]
UpdateEmbed:  62%|█████████████████▎          | 160/259 [01:13<00:45,  2.20it/s]
UpdateEmbed:  62%|█████████████████▍          | 161/259 [01:13<00:44,  2.22it/s]
UpdateEmbed:  63%|█████████████████▌          | 162/259 [01:14<00:43,  2.23it/s]
UpdateEmbed:  63%|█████████████████▌          | 163/259 [01:14<00:43,  2.22it/s]
UpdateEmbed:  63%|█████████████████▋          | 164/259 [01:14<00:42,  2.21it/s]
UpdateEmbed:  64%|█████████████████▊          | 165/259 [01:15<00:42,  2.23it/s]
UpdateEmbed:  64%|█████████████████▉          | 166/259 [01:15<00:41,  2.24it/s]
UpdateEmbed:  64%|██████████████████          | 167/259 [01:16<00:41,  2.21it/s]
UpdateEmbed:  65%|██████████████████▏         | 168/259 [01:16<00:41,  2.21it/s]
UpdateEmbed:  65%|██████████████████▎         | 169/259 [01:17<00:39,  2.26it/s]
UpdateEmbed:  66%|██████████████████▍         | 170/259 [01:17<00:39,  2.26it/s]
UpdateEmbed:  66%|██████████████████▍         | 171/259 [01:18<00:39,  2.22it/s]
UpdateEmbed:  66%|██████████████████▌         | 172/259 [01:18<00:38,  2.26it/s]
UpdateEmbed:  67%|██████████████████▋         | 173/259 [01:18<00:38,  2.25it/s]
UpdateEmbed:  67%|██████████████████▊         | 174/259 [01:19<00:37,  2.27it/s]
UpdateEmbed:  68%|██████████████████▉         | 175/259 [01:19<00:37,  2.25it/s]
UpdateEmbed:  68%|███████████████████         | 176/259 [01:20<00:37,  2.23it/s]
UpdateEmbed:  68%|███████████████████▏        | 177/259 [01:20<00:36,  2.28it/s]
UpdateEmbed:  69%|███████████████████▏        | 178/259 [01:21<00:36,  2.20it/s]
UpdateEmbed:  69%|███████████████████▎        | 179/259 [01:21<00:36,  2.20it/s]
UpdateEmbed:  69%|███████████████████▍        | 180/259 [01:22<00:36,  2.18it/s]
UpdateEmbed:  70%|███████████████████▌        | 181/259 [01:22<00:35,  2.18it/s]
UpdateEmbed:  70%|███████████████████▋        | 182/259 [01:23<00:34,  2.20it/s]
UpdateEmbed:  71%|███████████████████▊        | 183/259 [01:23<00:34,  2.21it/s]
UpdateEmbed:  71%|███████████████████▉        | 184/259 [01:23<00:34,  2.18it/s]
UpdateEmbed:  71%|████████████████████        | 185/259 [01:24<00:33,  2.20it/s]
UpdateEmbed:  72%|████████████████████        | 186/259 [01:24<00:32,  2.24it/s]
UpdateEmbed:  72%|████████████████████▏       | 187/259 [01:25<00:32,  2.21it/s]
UpdateEmbed:  73%|████████████████████▎       | 188/259 [01:25<00:32,  2.20it/s]
UpdateEmbed:  73%|████████████████████▍       | 189/259 [01:26<00:31,  2.22it/s]
UpdateEmbed:  73%|████████████████████▌       | 190/259 [01:26<00:30,  2.26it/s]
UpdateEmbed:  74%|████████████████████▋       | 191/259 [01:27<00:30,  2.26it/s]
UpdateEmbed:  74%|████████████████████▊       | 192/259 [01:27<00:29,  2.28it/s]
UpdateEmbed:  75%|████████████████████▊       | 193/259 [01:27<00:29,  2.25it/s]
UpdateEmbed:  75%|████████████████████▉       | 194/259 [01:28<00:28,  2.25it/s]
UpdateEmbed:  75%|█████████████████████       | 195/259 [01:28<00:28,  2.25it/s]
UpdateEmbed:  76%|█████████████████████▏      | 196/259 [01:29<00:27,  2.28it/s]
UpdateEmbed:  76%|█████████████████████▎      | 197/259 [01:29<00:27,  2.27it/s]
UpdateEmbed:  76%|█████████████████████▍      | 198/259 [01:30<00:27,  2.23it/s]
UpdateEmbed:  77%|█████████████████████▌      | 199/259 [01:30<00:26,  2.22it/s]
UpdateEmbed:  77%|█████████████████████▌      | 200/259 [01:31<00:26,  2.23it/s]
UpdateEmbed:  78%|█████████████████████▋      | 201/259 [01:31<00:26,  2.22it/s]
UpdateEmbed:  78%|█████████████████████▊      | 202/259 [01:31<00:25,  2.22it/s]
UpdateEmbed:  78%|█████████████████████▉      | 203/259 [01:32<00:25,  2.20it/s]
UpdateEmbed:  79%|██████████████████████      | 204/259 [01:32<00:25,  2.18it/s]
UpdateEmbed:  79%|██████████████████████▏     | 205/259 [01:33<00:24,  2.19it/s]
UpdateEmbed:  80%|██████████████████████▎     | 206/259 [01:33<00:24,  2.17it/s]
UpdateEmbed:  80%|██████████████████████▍     | 207/259 [01:34<00:24,  2.13it/s]
UpdateEmbed:  80%|██████████████████████▍     | 208/259 [01:34<00:23,  2.15it/s]
UpdateEmbed:  81%|██████████████████████▌     | 209/259 [01:35<00:22,  2.20it/s]
UpdateEmbed:  81%|██████████████████████▋     | 210/259 [01:35<00:22,  2.20it/s]
UpdateEmbed:  81%|██████████████████████▊     | 211/259 [01:36<00:21,  2.21it/s]
UpdateEmbed:  82%|██████████████████████▉     | 212/259 [01:36<00:21,  2.19it/s]
UpdateEmbed:  82%|███████████████████████     | 213/259 [01:37<00:21,  2.16it/s]
UpdateEmbed:  83%|███████████████████████▏    | 214/259 [01:37<00:21,  2.12it/s]
UpdateEmbed:  83%|███████████████████████▏    | 215/259 [01:38<00:21,  2.09it/s]
UpdateEmbed:  83%|███████████████████████▎    | 216/259 [01:38<00:20,  2.11it/s]
UpdateEmbed:  84%|███████████████████████▍    | 217/259 [01:38<00:19,  2.19it/s]
UpdateEmbed:  84%|███████████████████████▌    | 218/259 [01:39<00:18,  2.17it/s]
UpdateEmbed:  85%|███████████████████████▋    | 219/259 [01:39<00:18,  2.20it/s]
UpdateEmbed:  85%|███████████████████████▊    | 220/259 [01:40<00:17,  2.20it/s]
UpdateEmbed:  85%|███████████████████████▉    | 221/259 [01:40<00:17,  2.20it/s]
UpdateEmbed:  86%|████████████████████████    | 222/259 [01:41<00:16,  2.23it/s]
UpdateEmbed:  86%|████████████████████████    | 223/259 [01:41<00:16,  2.24it/s]
UpdateEmbed:  86%|████████████████████████▏   | 224/259 [01:42<00:15,  2.24it/s]
UpdateEmbed:  87%|████████████████████████▎   | 225/259 [01:42<00:14,  2.29it/s]
UpdateEmbed:  87%|████████████████████████▍   | 226/259 [01:42<00:14,  2.28it/s]
UpdateEmbed:  88%|████████████████████████▌   | 227/259 [01:43<00:14,  2.27it/s]
UpdateEmbed:  88%|████████████████████████▋   | 228/259 [01:43<00:13,  2.27it/s]
UpdateEmbed:  88%|████████████████████████▊   | 229/259 [01:44<00:13,  2.24it/s]
UpdateEmbed:  89%|████████████████████████▊   | 230/259 [01:44<00:13,  2.20it/s]
UpdateEmbed:  89%|████████████████████████▉   | 231/259 [01:45<00:12,  2.18it/s]
UpdateEmbed:  90%|█████████████████████████   | 232/259 [01:45<00:12,  2.15it/s]
UpdateEmbed:  90%|█████████████████████████▏  | 233/259 [01:46<00:11,  2.21it/s]
UpdateEmbed:  90%|█████████████████████████▎  | 234/259 [01:46<00:11,  2.25it/s]
UpdateEmbed:  91%|█████████████████████████▍  | 235/259 [01:46<00:10,  2.23it/s]
UpdateEmbed:  91%|█████████████████████████▌  | 236/259 [01:47<00:10,  2.26it/s]
UpdateEmbed:  92%|█████████████████████████▌  | 237/259 [01:47<00:09,  2.25it/s]
UpdateEmbed:  92%|█████████████████████████▋  | 238/259 [01:48<00:09,  2.29it/s]
UpdateEmbed:  92%|█████████████████████████▊  | 239/259 [01:48<00:08,  2.27it/s]
UpdateEmbed:  93%|█████████████████████████▉  | 240/259 [01:49<00:08,  2.25it/s]
UpdateEmbed:  93%|██████████████████████████  | 241/259 [01:49<00:07,  2.27it/s]
UpdateEmbed:  93%|██████████████████████████▏ | 242/259 [01:50<00:07,  2.25it/s]
UpdateEmbed:  94%|██████████████████████████▎ | 243/259 [01:50<00:07,  2.26it/s]
UpdateEmbed:  94%|██████████████████████████▍ | 244/259 [01:50<00:06,  2.30it/s]
UpdateEmbed:  95%|██████████████████████████▍ | 245/259 [01:51<00:06,  2.26it/s]
UpdateEmbed:  95%|██████████████████████████▌ | 246/259 [01:51<00:05,  2.23it/s]
UpdateEmbed:  95%|██████████████████████████▋ | 247/259 [01:52<00:05,  2.19it/s]
UpdateEmbed:  96%|██████████████████████████▊ | 248/259 [01:52<00:05,  2.18it/s]
UpdateEmbed:  96%|██████████████████████████▉ | 249/259 [01:53<00:04,  2.18it/s]
UpdateEmbed:  97%|███████████████████████████ | 250/259 [01:53<00:04,  2.20it/s]
UpdateEmbed:  97%|███████████████████████████▏| 251/259 [01:54<00:03,  2.23it/s]
UpdateEmbed:  97%|███████████████████████████▏| 252/259 [01:54<00:03,  2.25it/s]
UpdateEmbed:  98%|███████████████████████████▎| 253/259 [01:55<00:02,  2.21it/s]
UpdateEmbed:  98%|███████████████████████████▍| 254/259 [01:55<00:02,  2.23it/s]
UpdateEmbed:  98%|███████████████████████████▌| 255/259 [01:55<00:01,  2.23it/s]
UpdateEmbed:  99%|███████████████████████████▋| 256/259 [01:56<00:01,  2.23it/s]
UpdateEmbed:  99%|███████████████████████████▊| 257/259 [01:56<00:00,  2.28it/s]
UpdateEmbed: 100%|███████████████████████████▉| 258/259 [01:57<00:00,  2.25it/s]
UpdateEmbed: 100%|████████████████████████████| 259/259 [01:57<00:00,  2.20it/s]
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Testing DataLoader 0:   0%|                             | 0/104 [00:00<?, ?it/s]You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Testing DataLoader 0: 100%|███████████████████| 104/104 [29:26<00:00, 16.98s/it]
────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────
       Test/hits1           0.7492781520692974
       Test/hits10          0.9461020211742059
       Test/hits20           0.960538979788258
       Test/hits3           0.9100096246390761
       Test/hits5           0.9302213666987488
         Test/mr             106.9177093358999
        Test/mrr            0.8336887657480078
────────────────────────────────────────────────────────────────────────────────

Process finished with exit code 0
